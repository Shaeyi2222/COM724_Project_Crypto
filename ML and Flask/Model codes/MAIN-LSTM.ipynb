{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will import the necessary Library \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Evalution we will use these library\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For model building we will use these library\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "# For PLotting we will use these library\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#Important library imports...\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from numpy import set_printoptions\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06501acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data read in...\n",
    "crypto_data = pd.read_csv('./complete_dataset.csv')\n",
    "crypto_data.columns.values[0] = 'index'\n",
    "crypto_data.columns.values[1] = 'DateTime'\n",
    "#crypto_data.drop('index')\n",
    "crypto_data.drop(columns=['index'], inplace=True)\n",
    "crypto_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ab2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3add1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ensure the dataset is properly arranged by cryptocurrency and datetime stamp.\n",
    "df = crypto_data.sort_values(by=['Symbol', 'DateTime'])\n",
    "pd.to_datetime(df['DateTime'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63056db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veiwing other portions of the data and the other charcteristics\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff9de0",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "closedf = df[['DateTime', 'Close', 'Symbol']]\n",
    "print(closedf.head())\n",
    "\n",
    "groups = closedf.groupby('Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3446133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol, group_df in groups:\n",
    "#     fig = px.line(group_df, x=group_df.DateTime, y=group_df.Close,labels={'DateTime':'DateTime','Close':'Close Stock'}, title=f'{symbol} - Time vs Close')\n",
    "#     fig.update_traces(marker_line_width=2, opacity=0.8, marker_line_color='orange')\n",
    "#     # fig.update_layout(title_text='Whole period of timeframe of Bitcoin close price 2014-2022', plot_bgcolor='white', \n",
    "#     #                 font_size=15, font_color='black')\n",
    "#     fig.update_xaxes(showgrid=False, type='category')\n",
    "#     fig.update_yaxes(showgrid=False)\n",
    "#     #fig.show()\n",
    "\n",
    "#     #print(group_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4666720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1130ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c07e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter1Options = [\n",
    "      'APT-USD',\n",
    "      'ARB-USD',\n",
    "      'AVAX-USD',\n",
    "      'BNB-USD',\n",
    "      'BTC-USD',\n",
    "      'BCH-USD',\n",
    "      'ADA-USD',\n",
    "      'LINK-USD',\n",
    "      'DOGE-USD',\n",
    "      'ETH-USD',\n",
    "      'ETC-USD',\n",
    "      'HBAR-USD',\n",
    "      'LTC-USD',\n",
    "      'XMR-USD',\n",
    "      'MATIC-USD',\n",
    "      'SHIB-USD',\n",
    "      'SOL-USD',\n",
    "      'TRX-USD',\n",
    "      'WBTC-USD',\n",
    "      'XRP-USD'\n",
    "    ]\n",
    "\n",
    "\n",
    "#convert symbol into dummmy integer values\n",
    "\n",
    "for symbol, group_df in groups:\n",
    "    if symbol not in filter1Options:\n",
    "        print(f'{symbol} not in list...\\n')\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            #print(group_df.head())\n",
    "            use_symbol = symbol\n",
    "            new_group_df = group_df[['DateTime', 'Close']]\n",
    "            del group_df['Symbol']\n",
    "\n",
    "            #PLOT GRAPH\n",
    "            fig = px.line(new_group_df, x=new_group_df.DateTime, y=new_group_df.Close,labels={'DateTime':'DateTime','Close':'Close Stock'})\n",
    "            fig.update_traces(marker_line_width=2, opacity=0.8, marker_line_color='orange')\n",
    "            fig.update_layout(title_text=f'Whole period of timeframe of {use_symbol} close price 2014-2022', plot_bgcolor='white', \n",
    "                            font_size=15, font_color='black')\n",
    "            fig.update_xaxes(showgrid=False)\n",
    "            fig.update_yaxes(showgrid=False)\n",
    "            #fig.show()\n",
    "\n",
    "            del new_group_df['DateTime']\n",
    "            scaler=MinMaxScaler(feature_range=(0,1))\n",
    "            new_group_df=scaler.fit_transform(np.array(new_group_df).reshape(-1,1))\n",
    "            #print(new_group_df.shape)\n",
    "\n",
    "            # we keep the training set as 60% and 40% testing set\n",
    "\n",
    "            training_size=int(len(new_group_df)*0.60)\n",
    "            test_size=len(new_group_df)-training_size\n",
    "            train_data,test_data=new_group_df[0:training_size,:],new_group_df[training_size:len(new_group_df),:1]\n",
    "            print(\"train_data: \", train_data.shape)\n",
    "            print(\"test_data: \", test_data.shape)\n",
    "\n",
    "\n",
    "            time_step = 15\n",
    "            X_train, y_train = create_dataset(train_data, time_step)\n",
    "            X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "            print(\"X_train: \", X_train.shape)\n",
    "            print(\"y_train: \", y_train.shape)\n",
    "            print(\"X_test: \", X_test.shape)\n",
    "            print(\"y_test\", y_test.shape)\n",
    "\n",
    "            model=Sequential()\n",
    "\n",
    "            model.add(LSTM(10,input_shape=(None,1),activation=\"relu\"))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\n",
    "\n",
    "            history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=200,batch_size=32,verbose=1)\n",
    "\n",
    "            #import matplotlib.pyplot as plt\n",
    "\n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "\n",
    "            epochs = range(len(loss))\n",
    "\n",
    "            plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "            plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "            plt.title('Training and validation loss')\n",
    "            plt.legend(loc=0)\n",
    "            plt.figure()\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            ### Lets Do the prediction and check performance metrics\n",
    "            train_predict=model.predict(X_train)\n",
    "            test_predict=model.predict(X_test)\n",
    "            train_predict.shape, test_predict.shape\n",
    "\n",
    "            model.save(f'./All_Models/{use_symbol}.h5')\n",
    "\n",
    "            # Transform back to original form\n",
    "\n",
    "            train_predict = scaler.inverse_transform(train_predict)\n",
    "            test_predict = scaler.inverse_transform(test_predict)\n",
    "            original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) \n",
    "            original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) \n",
    "\n",
    "            # Evaluation metrices RMSE and MAE\n",
    "            print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
    "            print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
    "            print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
    "            print(\"-------------------------------------------------------------------------------------\")\n",
    "            print(\"Test data RMSE: \", math.sqrt(mean_squared_error(original_ytest,test_predict)))\n",
    "            print(\"Test data MSE: \", mean_squared_error(original_ytest,test_predict))\n",
    "            print(\"Test data MAE: \", mean_absolute_error(original_ytest,test_predict))\n",
    "\n",
    "\n",
    "            print(\"Train data explained variance regression score:\", \n",
    "                explained_variance_score(original_ytrain, train_predict))\n",
    "            print(\"Test data explained variance regression score:\", \n",
    "                explained_variance_score(original_ytest, test_predict))\n",
    "                \n",
    "            print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
    "            print(\"Test data R2 score:\", r2_score(original_ytest, test_predict))\n",
    "\n",
    "            print(\"Train data MGD: \", mean_gamma_deviance(original_ytrain, train_predict))\n",
    "            print(\"Test data MGD: \", mean_gamma_deviance(original_ytest, test_predict))\n",
    "            print(\"----------------------------------------------------------------------\")\n",
    "            print(\"Train data MPD: \", mean_poisson_deviance(original_ytrain, train_predict))\n",
    "            print(\"Test data MPD: \", mean_poisson_deviance(original_ytest, test_predict))\n",
    "\n",
    "\n",
    "            # shift train predictions for plotting\n",
    "\n",
    "            look_back=time_step\n",
    "            trainPredictPlot = np.empty_like(new_group_df)\n",
    "            trainPredictPlot[:, :] = np.nan\n",
    "            trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "            print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "            # shift test predictions for plotting\n",
    "            testPredictPlot = np.empty_like(new_group_df)\n",
    "            testPredictPlot[:, :] = np.nan\n",
    "            testPredictPlot[len(train_predict)+(look_back*2)+1:len(new_group_df)-1, :] = test_predict\n",
    "            print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "            names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "            print(group_df.head())\n",
    "\n",
    "            plotdf = pd.DataFrame({'date': group_df['DateTime'],\n",
    "                                'original_close': group_df['Close'],\n",
    "                                'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                                'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "            fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                                    plotdf['test_predicted_close']],\n",
    "                        labels={'value':'Stock price','date': 'DateTime'})\n",
    "            fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                            plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "            fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "            fig.update_xaxes(showgrid=False)\n",
    "            fig.update_yaxes(showgrid=False)\n",
    "            fig.show()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
